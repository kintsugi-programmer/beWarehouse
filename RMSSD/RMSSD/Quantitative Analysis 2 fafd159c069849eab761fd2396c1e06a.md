# Quantitative Analysis 2

Normal Probability Curve

Z-test

t-test

Video Explaining A to Z of t-tests

[https://www.youtube.com/watch?v=VekJxtk4BYM](https://www.youtube.com/watch?v=VekJxtk4BYM)

Z Test

[https://www.youtube.com/watch?v=bB-J6_wcGgE](https://www.youtube.com/watch?v=bB-J6_wcGgE)

Z and T-Test Explained

Z and t-test, another source

[https://www.youtube.com/watch?v=zJ8e_wAWUzE](https://www.youtube.com/watch?v=zJ8e_wAWUzE)

[**Hypothesis Testing.pptx**PowerPoint](https://drive.google.com/file/d/1-LXnNJAhMP53r-7d_KoxQVOMnL_QUKhf/view?usp=drive_web&authuser=0)

[https://lh3.googleusercontent.com/drive-storage/AKHj6E7LXr6BGpN2sS3BuLWvIajPWIrkFb9kzNTr1mr0rJSdBNDoxDwRfBj_nRtoPnOFCOnLHEFT8crZJ4A8qtxuQjdyiLkewGsojOklY1hG1Q=w105-h70-c](https://lh3.googleusercontent.com/drive-storage/AKHj6E7LXr6BGpN2sS3BuLWvIajPWIrkFb9kzNTr1mr0rJSdBNDoxDwRfBj_nRtoPnOFCOnLHEFT8crZJ4A8qtxuQjdyiLkewGsojOklY1hG1Q=w105-h70-c)

[**Hypothesis Testing_t test.pptx**PowerPoint](https://drive.google.com/file/d/1atuYv9bPR2MePIafr2kOoUbEuKClJKh3/view?usp=drive_web&authuser=0)

[https://lh3.googleusercontent.com/drive-storage/AKHj6E7gNtcyqGrnaoH89zmBOPFupdQr_cJTG2h5m65oLNIkQMtrx0s1wnfGop5YSiccIWtboQR9hOcSXEOK4EYquG_xQaAjnsTS56u_GdChKA=w105-h70-c](https://lh3.googleusercontent.com/drive-storage/AKHj6E7gNtcyqGrnaoH89zmBOPFupdQr_cJTG2h5m65oLNIkQMtrx0s1wnfGop5YSiccIWtboQR9hOcSXEOK4EYquG_xQaAjnsTS56u_GdChKA=w105-h70-c)

[**Case Problems.pptx**PowerPoint](https://drive.google.com/file/d/1Ia7dSGugw1pVsUIhzpQqMy11EP7rPt6b/view?usp=drive_web&authuser=0)

[https://lh3.googleusercontent.com/drive-storage/AKHj6E6nwCONORsQszKnDvechg60zOSwhzKbj7qaNJCwnHocf67Y4cr8gwe3VoaO2DtUXwGKQUhcem-zwa3J6XYAdhDIExde6NsjdoniRGs6-w=w105-h70-c](https://lh3.googleusercontent.com/drive-storage/AKHj6E6nwCONORsQszKnDvechg60zOSwhzKbj7qaNJCwnHocf67Y4cr8gwe3VoaO2DtUXwGKQUhcem-zwa3J6XYAdhDIExde6NsjdoniRGs6-w=w105-h70-c)

Sure, here is a summary of the key concepts and explanations from the provided text:

**Key Concepts:**

- **Representativeness:** A sample is representative if it accurately reflects the characteristics of the population from which it was drawn.
- **Generalizability:** The extent to which the results of a study can be applied to a broader context.
- **Reliability:** The consistency or precision of a measure.
- **Validity:** The accuracy of a measure.
- **Normal Distribution:** A probability distribution that is symmetrical about the mean and bell-shaped.
- **Standard Deviation:** A measure of the spread of data in a normal distribution.
- **Central Limit Theorem:** A statistical theorem that states that the mean of a sufficiently large sample from a population will be approximately equal to the population mean.
- **Z-scores:** Standard scores that represent the number of standard deviations a specific data point is away from the mean.
- **Z-test:** A statistical test used to compare the means of two groups or to compare the mean of a group to a known value.
- **p-value:** The probability of obtaining a result as extreme or more extreme than the observed result, assuming the null hypothesis is true.

**Explanations:**

- **Representativeness and Generalizability:**
    - Representativeness is crucial for generalizability. A representative sample increases the likelihood that the results of a study can be applied to the broader population.
- **Reliability and Validity:**
    - Reliability and validity are essential for the quality of research studies. A reliable measure produces consistent results, while a valid measure accurately measures what it is intended to measure.
- **Normal Distribution:**
    - The normal distribution is a common type of probability distribution that is bell-shaped and symmetrical about the mean. It is often used to model continuous data, such as height, weight, and IQ scores.
- **Standard Deviation:**
    - The standard deviation measures the spread of data in a normal distribution. It represents the average distance of data points from the mean.
- **Central Limit Theorem:**
    - The Central Limit Theorem states that the mean of a sufficiently large sample from a population will be approximately equal to the population mean, regardless of the distribution of the population.
- **Z-scores:**
    - Z-scores are standard scores that represent the number of standard deviations a specific data point is away from the mean. They allow for comparisons between data points from different normal distributions.
- **Z-test:**
    - The Z-test is used to compare the means of two groups or to compare the mean of a group to a known value. It calculates the z-score of the difference between the means and compares the p-value to a significance level.
- **p-value:**
    - The p-value represents the probability of obtaining a result as extreme or more extreme than the observed result, assuming the null hypothesis is true. A small p-value (typically less than 0.05) indicates that the observed result is unlikely to have occurred by chance and provides evidence against the null hypothesis.

These key concepts and explanations provide a foundation for understanding the concepts of representativeness, generalizability, reliability, validity, normal distribution, standard deviation, Central Limit Theorem, z-scores, z-test, and p-value in statistical research.

**Key Concepts in Sampling and Representativeness:**

1. **Representativeness:**
    - Definition: Drawing accurate conclusions about a population from a sample.
    - Indicator: A sample is representative if all elements had an equal chance of being part of it.
    - Relationship with Sample Size: Generally, representativeness increases with an increase in sample size.
2. **Stratification in Large Surveys:**
    - Approach: Researchers divide the population into strata based on characteristics like ethnicity, gender, age, income, or geography.
    - Goal: Ensure a representative sample that mirrors the essential properties of the population.
3. **Study Sample Representativeness:**
    - Definition: A study sample is representative if the results can be generalized to a well-defined target population.
    - Criteria: Generalizability is based on either the estimate obtained or the interpretation of results in the sample.
4. **Representativeness vs. Representation:**
    - Distinction: Representativeness is a feature of statistical research, different from representation.

**Key Concepts in Generalizability:**

1. **Definition:**
    - Generalizability: The measure of how applicable study results are to a broader context.
    - External Validity: Determined by the representativeness of the sample concerning the target population.
2. **Factors Influencing Generalizability:**
    - Three Determinants: Randomness of the sample, representativeness, and the size of the sample.
    - Challenge: Addressing biases like WWIB (white, Western, individualist bias).
3. **Importance of Generalizability:**
    - Significance: Crucial for establishing the validity and reliability of a study.

**Key Concepts in Reliability and Validity:**

1. **Reliability:**
    - Definition: The extent to which results can be reproduced under the same conditions.
    - Assessment: Consistency across time, observers, and test components.
    - Caution: Reliability does not guarantee validity; reproducible results may not be correct.
2. **Validity:**
    - Definition: The extent to which results measure what they are supposed to.
    - Assessment: Correspondence with established theories and other measures.
    - Relationship with Reliability: A valid measurement is generally reliable.

**Types of Reliability and Reproducibility:**

1. **Test-Retest Reliability:**
    - Definition: Consistency of a measure across time.
2. **Reproducibility vs. Replicability:**
    - Reproducibility: Reanalyzing existing data using the same methods for consistent results.
    - Replicability: Conducting the entire research process again with new data for the same results.
    - Distinction: A study can be reproducible but not replicable.

**Enhancing Research Quality:**

1. **Importance of Reproducibility and Replicability:**
    - Purpose: Both enhance research quality and check bias.
    - Reproducibility Focus: Transparency and informativeness.
    - Requirements: Availability of raw data for transparent analysis, reducing the risk of information bias.
    

Sure, here is a structured explanation of the key concepts:

**Representativeness**

- Definition: Representativeness refers to the extent to which a sample mirrors a population and reflects its essential properties.
- Importance: A representative sample allows researchers to draw accurate conclusions about the population from the sample.
- Factors Affecting Representativeness:
    - Sample Size: Larger samples tend to be more representative of the population.
    - Stratification: Dividing a population into strata based on relevant characteristics can ensure representativeness.
- Relationship to Generalizability: Representativeness is a key factor in determining the generalizability of research findings.

**Generalizability**

- Definition: Generalizability refers to the extent to which research findings can be applied to a broader context.
- Importance: Generalizable research findings have wider applicability and contribute to broader knowledge.
- Factors Affecting Generalizability:
    - Representativeness: A representative sample is crucial for generalizable findings.
    - Sample Size: Larger samples generally provide more generalizable findings.
    - WWIB (White, Western, Individualist) Bias: Over-representation of Western, educated, industrialized, rich, and democratic (WEIRD) populations can limit generalizability.
- Relationship to Validity: Generalizability is an aspect of external validity, which assesses the extent to which research findings can be generalized to other settings or populations.

**Reliability and Validity**

- Reliability: Reliability refers to the consistency or precision of a measure, indicating whether it produces consistent results across different contexts and measurements.
    - Assessing Reliability: Reliability is assessed by checking the consistency of results across time, across different observers, and across parts of the test itself.
    - Relationship to Validity: A reliable measurement is not always valid, as it may produce consistent results that are not accurate.
- Validity: Validity refers to the extent to which a measure accurately reflects what it is supposed to measure, indicating whether it measures what it intends to measure.
    - Assessing Validity: Validity is assessed by checking how well the results correspond to established theories and other measures of the same concept.
    - Relationship to Reliability: A valid measurement is generally reliable, as accurate results tend to be consistent.

**Reproducibility and Replicability**

- Reproducibility: Reproducibility refers to the ability to reanalyze existing data using the same research methods and obtain the same results.
    - Importance: Reproducibility ensures that the analysis was conducted fairly and correctly.
- Replicability: Replicability refers to the ability to conduct the entire research process again, using the same methods but new data, and obtain the same results.
    - Importance: Replicability demonstrates the reliability of the original study's findings.
- Relationship: A study may be reproducible but not replicable.
    - Importance: Both reproducibility and replicability enhance the quality of research and help identify potential biases.

**Enhancing Reproducibility**

- Transparency: Making all necessary raw data available allows others to reanalyze the data and verify the findings.
- Avoiding Biases: Omitted variables, missing data, or mistakes can lead to information bias and hinder reproducibility.

Sure, I can provide a structured summary of the provided text:

## **Normal Distribution and Hypothesis Testing**

**Normal Distribution**

- A normal distribution is a bell-shaped curve that represents the probability of different values occurring in a population.
- It is characterized by two parameters: the mean (μ) and the standard deviation (σ).
- The empirical rule, or the 68-95-99.7 rule, states that:
    - Approximately 68% of values fall within 1 standard deviation of the mean.
    - Approximately 95% of values fall within 2 standard deviations of the mean.
    - Approximately 99.7% of values fall within 3 standard deviations of the mean.

**Hypothesis Testing**

- Hypothesis testing is a statistical procedure used to determine whether there is enough evidence to reject a null hypothesis (H₀) in favor of an alternative hypothesis (Hₐ).
- The null hypothesis is typically the assumption that there is no difference or effect, while the alternative hypothesis is the opposite.
- The level of significance (α) is the probability of rejecting the null hypothesis when it is actually true (type I error).
- The p-value is the probability of obtaining a result as extreme or more extreme than the observed result, assuming the null hypothesis is true.
- If the p-value is less than or equal to α, then we reject the null hypothesis. Otherwise, we fail to reject the null hypothesis.

**Types of Hypothesis Tests**

- Z-test: Used when the population standard deviation is known or the sample size is large (n > 30).
- t-test: Used when the population standard deviation is unknown or the sample size is small (n < 30).
- Chi-square test: Used to compare categorical data.

**Additional Concepts**

- Skewness: The degree of asymmetry in a distribution.
- Kurtosis: The peakedness of a distribution.
- Pearson's correlation coefficient (r): A measure of the strength and direction of the linear relationship between two variables.

**Examples**

- **Example 1:** A sleep researcher wants to know if sleep habits changed during the COVID-19 lockdown. They collect sleep duration data from a sample during a full lockdown. Before the lockdown, the population mean was 6.5 hours of sleep. The lockdown sample mean is 7.62 hours. Using a z-test, they find that the p-value is less than 0.05. They conclude that average sleep duration in the COVID-19 lockdown was significantly higher than the pre-lockdown average.
- **Example 2:** An e-commerce website wants to know if changing the color schemes and color gradients of the website will increase the average impressions per user. They run an A/B test and find that the p-value is 0.2. They fail to reject the null hypothesis, meaning there is not enough evidence to say that the new design increased impressions.

I hope this summary is helpful. Please let me know if you have any other questions.

# Summary: Normal Distribution, Hypothesis Testing, and Statistical Concepts

## Normal Distribution:

- **Definition:** A bell-shaped probability distribution symmetric around the mean.
- **Parameters:** Described by mean (µ) and standard deviation (σ).
- **Properties:** Symmetry, unimodal, continuous, and described by the empirical rule (68-95-99.7).
- **Use Cases:** Commonly observed in variables like IQ, height, and job satisfaction.

## Skewness and Kurtosis:

- **Skewness:** Measures asymmetry; positive (left-skewed) or negative (right-skewed).
- **Kurtosis:** Measures the shape; leptokurtic (high peak), platykurtic (flat-topped), or mesokurtic (normal).
- **Pearson’s Coefficient of Skewness:** Indicates the degree and direction of skewness.
- **Expected Kurtosis:** 3, values less or more indicate negative or positive kurtosis.

## Central Limit Theorem (CLT) and Standard Normal Distribution:

- **CLT:** States that the mean of sufficiently large samples from a population equals the population mean.
- **Standard Normal Distribution:** Mean (µ) = 0, Standard Deviation (σ) = 1, represented by Z-scores.

## Probability Using Z-Distribution:

- **Z-Tests and P Values:** Used for statistical decision-making.
- **P Value:** Probability of values below or above a Z score.
- **Significance Level:** Typically set at 0.05; p < 0.05 indicates statistical significance.

## Hypothesis Testing:

- **Z-Test and T-Test:** Compare means or test assumptions about populations.
- **Key Assumptions:** Data independence, normal distribution.
- **Types of t-Tests:** Paired, two-sample, one-sample based on experimental design.

## Pearson’s Correlation (r):

- **Interpretation:** Measures linear correlation between two variables.
- **Effect Size:** Indicates the strength of the relationship.
- **Hypothesis Testing:** Tests if there's a significant relationship between variables.

## A/B Testing:

- **Purpose:** Compare two designs or treatments.
- **Case Problem Examples:**
    - Time spent on website: Not statistically significant.
    - Impressions per user: Not statistically significant.
    - Watch time on e-commerce website: Result not significant.

## Summary of Case Problems:

- [**Expoze.io](http://expoze.io/) Homepage Test:** No evidence of significant change in user attention.
- **E-commerce Impressions Test:** No evidence of a significant difference.
- **E-commerce Watch Time Test:** Result not statistically significant, no evidence of a difference.

In conclusion, understanding normal distribution, hypothesis testing, and statistical concepts is crucial for analyzing data, making informed decisions, and drawing meaningful conclusions.

Sure, let's delve into the concepts of normal distribution, hypothesis testing, and related statistical concepts. I'll provide formulas and examples for better understanding.

### Normal Distribution:

The normal distribution is a continuous probability distribution characterized by a bell-shaped curve. It is defined by two parameters: the mean (μ) and the standard deviation (σ).

**Probability Density Function (PDF) Formula:**
\[ f(x | \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2} \]

**Empirical Rule (68-95-99.7 Rule):**

- Approximately 68% of values fall within 1 standard deviation of the mean.
- Approximately 95% of values fall within 2 standard deviations of the mean.
- Approximately 99.7% of values fall within 3 standard deviations of the mean.

### Hypothesis Testing:

**Null Hypothesis (H₀) and Alternative Hypothesis (Hₐ):**

- H₀: The assumption that there is no difference or effect.
- Hₐ: The opposite of the null hypothesis.

**Level of Significance (α):**

- The probability of rejecting the null hypothesis when it is actually true (type I error).

**p-value:**

- The probability of obtaining a result as extreme or more extreme than the observed result, assuming the null hypothesis is true.

**Decision Rule:**

- If p-value ≤ α, reject the null hypothesis.
- If p-value > α, fail to reject the null hypothesis.

### Types of Hypothesis Tests:

1. **Z-test:**
    - Used when the population standard deviation is known or the sample size is large (n > 30).
    - Formula: \[ Z = \frac{\bar{X} - \mu}{\frac{\sigma}{\sqrt{n}}} \]
    - Example: A sleep researcher comparing average sleep duration during lockdown (\(\bar{X} = 7.62\)) to the pre-lockdown mean (\(\mu = 6.5\)) using a z-test.
2. **t-test:**
    - Used when the population standard deviation is unknown or the sample size is small (n < 30).
    - Formula: \[ t = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}} \]
    - Example: An e-commerce website running an A/B test with a sample mean (\(\bar{X}\)), population mean (\(\mu\)), sample standard deviation (\(s\)), and sample size (\(n\)).
3. **Chi-square test:**
    - Used to compare categorical data.
    - Formula depends on the specific chi-square test being used.

### Additional Concepts:

1. **Skewness:**
    - Measures the degree of asymmetry in a distribution.
    - Formula: \( \text{Skewness} = \frac{3(\bar{X} - \mu)}{s} \)
2. **Kurtosis:**
    - Measures the peakedness of a distribution.
    - Formula depends on the specific kurtosis measure being used.
3. **Pearson's Correlation Coefficient (r):**
    - Measures the strength and direction of the linear relationship between two variables.
    - Formula: \[ r = \frac{\sum{(X_i - \bar{X})(Y_i - \bar{Y})}}{\sqrt{\sum{(X_i - \bar{X})^2}\sum{(Y_i - \bar{Y})^2}}} \]

### Examples:

**Example 1 (Z-test):**

- Given: \(\bar{X} = 7.62\), \(\mu = 6.5\), \(\sigma\) (known), \(n\) (sample size).
- Calculate the z-value and compare to the critical z-value at \(\alpha\) level.

**Example 2 (t-test):**

- Given: \(\bar{X}\), \(\mu\), \(s\), \(n\).
- Calculate the t-value and compare to the critical t-value at \(\alpha\) level.

**Example 3 (Pearson's r):**

- Given paired data (X, Y), calculate the correlation coefficient using the formula.

Remember, these are simplified examples, and real-world applications may involve additional considerations and complexities.

- Normal distribution
- Empirical rule (68-95-99.7 rule)
- Mean (μ)
- Standard deviation (σ)
- Hypothesis testing
- Null hypothesis (H₀)
- Alternative hypothesis (Hₐ)
- Level of significance (α)
- p-value
- Type I error
- Type II error
- Z-test
- t-test
- Chi-square test
- Skewness
- Kurtosis
- Pearson's correlation coefficient (r)